// These constants represent the RISC-V ELF and the image ID generated by risc0-build.
// The ELF is used for proving and the ID is used for verification.
use anyhow::{Context, Error};
use nexus_core::{
    db::NodeDB,
    mempool::Mempool,
    state_machine::StateMachine,
    types::{AvailHeader, HeaderStore, NexusHeader, TransactionV2, H256},
};
use prover::{NEXUS_RUNTIME_ELF, NEXUS_RUNTIME_ID};
use relayer::Relayer;
use risc0_zkvm::{default_executor, default_prover, serde::from_slice, ExecutorEnv, Receipt};
use std::sync::Arc;
use tokio::{self, sync::Mutex};
use warp::Filter;

use std::net::SocketAddr;
use std::str::FromStr;

use crate::rpc::routes;

pub mod rpc;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let db = NodeDB::from_path(String::from("./node_db"));
    let old_state_root: H256 = match db.get_current_root()? {
        Some(i) => i,
        None => H256::zero(),
    };
    let mut state_machine = StateMachine::new(old_state_root, "./runtime_db");
    let relayer = Relayer::new();
    let shared_relayer = Arc::new(Mutex::new(relayer));

    // let init_tx = TransactionV2 {
    //     signature: TxSignature([0; 64]),
    //     params: TxParamsV2::InitAccount(InitAccount {
    //         app_id: AppAccountId::from(AppId(1)),
    //         statement: [1; 32],
    //     }),
    // };
    // let txs: Vec<TransactionV2> = vec![init_tx];

    let rt = tokio::runtime::Runtime::new().unwrap();
    rt.block_on(async move {
        let receiver = {
            let mut relayer = shared_relayer.lock().await;

            relayer.receiver()
        };
        let mempool = Mempool::new();
        let mempool_clone = mempool.clone();

        let relayer = tokio::spawn(async move {
            let cloned_relayer = shared_relayer.lock().await;
            println!("Trying to start");
            println!("started from our side bro");
            cloned_relayer.start().await;
        });

        let execution_engine = tokio::spawn(async move {
            while let Some(header) = receiver.lock().await.recv().await {
                let mut old_headers: HeaderStore = match db.get(b"previous_headers") {
                    Ok(Some(i)) => i,
                    Ok(None) => HeaderStore::new(32),
                    Err(_) => break,
                };
                let (txs, index) = mempool_clone.get_current_txs().await;
                //let (txs, index) = (vec![], 0);

                match execute_batch(
                    &AvailHeader::from(&header),
                    &mut old_headers,
                    &txs,
                    &db,
                    &mut state_machine,
                ) {
                    Ok(_) => mempool_clone.clear_upto_tx(index).await,
                    Err(e) => {
                        println!("Breaking because of error {:?}", e);
                        break;
                    }
                };
            }
        });

        //Server part//
        let routes = routes(mempool);
        let cors = warp::cors()
            .allow_any_origin()
            .allow_methods(vec!["POST"])
            .allow_headers(vec!["content-type"]);
        let routes = routes.with(cors);
        let server: tokio::task::JoinHandle<()> = tokio::spawn(async move {
            println!("trying to start rpc server");
            let address =
                SocketAddr::from_str(format!("{}:{}", String::from("127.0.0.1"), 7000).as_str())
                    .context("Unable to parse host address from config")
                    .unwrap();

            println!("RPC Server running on: {:?}", &address);
            warp::serve(routes).run(address).await;
        });

        //start_rpc_server().await;

        let result = tokio::try_join!(server, execution_engine, relayer);

        match result {
            Ok((_, _, _)) => {
                println!("Exiting node, should not have happened.");
            }
            Err(e) => {
                println!("Exiting node, should not have happened. {:?}", e);
            }
        }
    });

    Ok(())
}

fn execute_batch(
    new_header: &AvailHeader,
    old_headers: &mut HeaderStore,
    txs: &Vec<TransactionV2>,
    db: &NodeDB,
    state_machine: &mut StateMachine,
) -> Result<Receipt, Error> {
    let mut cloned_old_headers = old_headers.clone();
    let state_update = state_machine.execute_batch(&new_header, &mut cloned_old_headers, &txs)?;

    let env = ExecutorEnv::builder()
        .write(&new_header)
        .unwrap()
        .write(&old_headers)
        .unwrap()
        .write(&txs)
        .unwrap()
        .write(&state_update)
        .unwrap()
        .build()
        .unwrap();

    let exec = default_executor();
    let session_info = exec.execute(env, NEXUS_RUNTIME_ELF).unwrap();
    let cycles = session_info
        .segments
        .iter()
        .fold(0, |cycles, segment| (cycles + (1 << segment.po2)));
    let cycles = cycles as u32;

    let result: NexusHeader = from_slice(&session_info.journal.bytes).unwrap();

    db.put(b"previous_headers", &cloned_old_headers)?;

    db.set_current_root(&result.state_root)?;

    println!("{:?}, no of cycles: {:?}", result, cycles);

    //Proof generation part.
    let env = ExecutorEnv::builder()
        .write(&new_header)
        .unwrap()
        .write(&old_headers)
        .unwrap()
        .write(&txs)
        .unwrap()
        .write(&state_update)
        .unwrap()
        .build()
        .unwrap();
    let prover = default_prover();

    println!("generating proof..");
    Ok(prover.prove(env, NEXUS_RUNTIME_ELF)?)
}
